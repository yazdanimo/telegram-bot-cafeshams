import requests
from bs4 import BeautifulSoup
from translatepy import Translator
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lsa import LsaSummarizer
from langdetect import detect
from utils import extract_image_from_html
import json

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù„ÛŒØ³Øª Ù…Ù†Ø§Ø¨Ø¹ Ø§Ø² ÙØ§ÛŒÙ„
with open("sources.json", "r", encoding="utf-8") as f:
    sources = json.load(f)

translator = Translator()

def summarize_text(text, sentence_count=3):
    try:
        parser = PlaintextParser.from_string(text, Tokenizer("english"))
        summarizer = LsaSummarizer()
        summary = summarizer(parser.document, sentence_count)
        return " ".join(str(sentence) for sentence in summary)
    except Exception:
        return text[:400]  # Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ØŒ Ø®Ù„Ø§ØµÙ‡ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¨Ø±Ø´

async def fetch_and_send_news(bot, chat_id, sent_urls):
    total_items = 0
    total_duplicates = 0
    total_sent = 0
    any_news_sent = False

    for source in sources:
        name = source.get("name")
        url = source.get("url")

        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª {name}: {e}")
            continue

        soup = BeautifulSoup(response.content, "xml")
        items = soup.find_all("item")
        print(f"\nğŸ“¡ Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù†Ø¨Ø¹: {name} â†’ {url}")
        print(f"ğŸ”¸ Ù…Ø¬Ù…ÙˆØ¹ Ø®Ø¨Ø±Ù‡Ø§: {len(items)}")

        for item in items[:5]:
            title = item.title.text.strip() if item.title else "Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†"
            link = item.link.text.strip() if item.link else ""
            description = item.description.text.strip() if item.description else ""
            image_url = extract_image_from_html(description)

            if not link or link in sent_urls:
                total_duplicates += 1
                continue

            sent_urls.add(link)
            total_items += 1

            combined_text = f"{title}. {description}"

            try:
                lang = detect(combined_text)
            except:
                lang = "unknown"

            if lang not in ["en", "fa"]:
                try:
                    combined_text = translator.translate(combined_text, "English").result
                except:
                    pass

            summary = summarize_text(combined_text, sentence_count=3)

            if lang == "en":
                try:
                    summary = translator.translate(summary, "Persian").result
                except:
                    pass

            # Ú©Ù¾Ø´Ù† Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø¯ÙˆÙ† Ù„ÛŒÙ†Ú©
            caption = (
                f"ğŸ“° {name}\n"
                f"ğŸ”¸ {title}\n\n"
                f"ğŸ“ƒ {summary.strip()}\n\n"
                f"ğŸ–Š Ú¯Ø²Ø§Ø±Ø´ Ø§Ø² {name} | @cafeshamss"
            )

            try:
                if image_url:
                    await bot.send_photo(chat_id=chat_id, photo=image_url, caption=caption[:1024])
                else:
                    await bot.send_message(chat_id=chat_id, text=caption[:4096])
                print(f"âœ… Ø®Ø¨Ø± Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯ Ø§Ø² {name}")
                total_sent += 1
                any_news_sent = True
            except Exception as e:
                print(f"â—ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø§Ø² {name}: {e}")

    print("\nğŸ“Š Ø¢Ù…Ø§Ø± Ø§Ø¬Ø±Ø§ÛŒ ÙØ¹Ù„ÛŒ:")
    print(f"ğŸ”¹ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ù†Ø§Ø¨Ø¹: {len(sources)}")
    print(f"ğŸ”¹ Ø®Ø¨Ø±Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø§Ø±Ø³Ø§Ù„â€ŒØ´Ø¯Ù‡: {total_sent}")
    print(f"ğŸ”¹ Ø®Ø¨Ø±Ù‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ: {total_duplicates}")
    print(f"ğŸ”¹ Ø¬Ù…Ø¹ Ø®Ø¨Ø±Ù‡Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒâ€ŒØ´Ø¯Ù‡: {total_items + total_duplicates}")
    if not any_news_sent:
        print("âš ï¸ Ø¯Ø± Ø§ÛŒÙ† Ù†ÙˆØ¨Øª Ù‡ÛŒÚ† Ø®Ø¨Ø±ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù†Ø´Ø¯.")

    return sent_urls
