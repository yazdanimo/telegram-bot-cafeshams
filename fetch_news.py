import requests
from bs4 import BeautifulSoup
from translatepy import Translator
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lsa import LsaSummarizer
from langdetect import detect
from utils import extract_image_from_html
import json

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ù†Ø§Ø¨Ø¹
with open("sources.json", "r", encoding="utf-8") as f:
    sources = json.load(f)

translator = Translator()

def summarize_text(text, sentence_count=3):
    try:
        parser = PlaintextParser.from_string(text, Tokenizer("english"))
        summarizer = LsaSummarizer()
        summary = summarizer(parser.document, sentence_count)
        return " ".join(str(sentence) for sentence in summary)
    except Exception:
        return text[:400]

async def fetch_and_send_news(bot, chat_id, sent_urls):
    total_items = 0
    total_duplicates = 0
    total_sent = 0
    any_news_sent = False

    for source in sources:
        name = source.get("name")
        url = source.get("url")

        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª {name}: {e}")
            continue

        soup = BeautifulSoup(response.content, "xml")
        items = soup.find_all("item")
        print(f"\nğŸ“¡ Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù†Ø¨Ø¹: {name} â†’ {url}")
        print(f"ğŸ”¸ Ù…Ø¬Ù…ÙˆØ¹ Ø®Ø¨Ø±Ù‡Ø§: {len(items)}")

        for item in items[:5]:
            title = item.title.text.strip() if item.title else "Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†"
            link = item.link.text.strip() if item.link else ""
            description = item.description.text.strip() if item.description else ""
            image_url = extract_image_from_html(description)

            # ÙÛŒÙ„ØªØ± ØªÛŒØªØ±Ù‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ ÛŒØ§ Ø¨Ø¯ÙˆÙ† Ù„ÛŒÙ†Ú©
            if not link or link in sent_urls:
                total_duplicates += 1
                continue

            sent_urls.add(link)
            total_items += 1

            # ÙÛŒÙ„ØªØ± ØªÛŒØªØ±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ "Ø¹Ú©Ø³/" Ø´Ø±ÙˆØ¹ Ù…ÛŒâ€ŒØ´Ù† Ø§Ù…Ø§ ØªØµÙˆÛŒØ± Ù†Ø¯Ø§Ø±Ù†
            if title.startswith("Ø¹Ú©Ø³/") and not image_url:
                print(f"âš ï¸ Ø®Ø¨Ø± ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø¯ÙˆÙ† Ø¹Ú©Ø³ Ø§Ø² {name} â†’ Ø±Ø¯ Ø´Ø¯")
                continue

            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ø®Ø¨Ø± Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø²Ø¨Ø§Ù† Ùˆ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ
            combined_text = f"{title}. {description}"
            try:
                lang = detect(combined_text)
            except:
                lang = "unknown"

            if lang not in ["en", "fa"]:
                try:
                    combined_text = translator.translate(combined_text, "English").result
                except:
                    pass

            summary = summarize_text(combined_text, sentence_count=3)

            if lang == "en":
                try:
                    summary = translator.translate(summary, "Persian").result
                except:
                    pass

            # Ø³Ø§Ø®Øª Ú©Ù¾Ø´Ù† Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø¯ÙˆÙ† Ù„ÛŒÙ†Ú©
            caption = (
                f"ğŸ“° {name}\n"
                f"ğŸ”¸ {title.strip()}\n\n"
                f"ğŸ“ƒ {summary.strip()}\n\n"
                f"ğŸ–Š Ú¯Ø²Ø§Ø±Ø´ Ø§Ø² {name} | @cafeshamss"
            )

            try:
                if image_url:
                    await bot.send_photo(chat_id=chat_id, photo=image_url, caption=caption[:1024])
                else:
                    await bot.send_message(chat_id=chat_id, text=caption[:4096])
                print(f"âœ… Ø®Ø¨Ø± Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯ Ø§Ø² {name}")
                total_sent += 1
                any_news_sent = True
            except Exception as e:
                print(f"â—ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø§Ø² {name}: {e}")

    print("\nğŸ“Š Ø¢Ù…Ø§Ø± Ø§Ø¬Ø±Ø§ÛŒ ÙØ¹Ù„ÛŒ:")
    print(f"ğŸ”¹ ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ø¨Ø¹ Ø¨Ø±Ø±Ø³ÛŒâ€ŒØ´Ø¯Ù‡: {len(sources)}")
    print(f"ğŸ”¹ Ø®Ø¨Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„â€ŒØ´Ø¯Ù‡: {total_sent}")
    print(f"ğŸ”¹ Ø®Ø¨Ø±Ù‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ: {total_duplicates}")
    if not any_news_sent:
        print("âš ï¸ Ù‡ÛŒÚ† Ø®Ø¨Ø±ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù†Ø´Ø¯.")

    return sent_urls
