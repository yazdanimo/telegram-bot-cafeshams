import requests
from bs4 import BeautifulSoup
import json

def validate_sources(input_file="sources.json", output_file="sources_valid.json"):
    try:
        with open(input_file, "r", encoding="utf-8") as f:
            sources = json.load(f)
    except Exception as e:
        print(f"â—ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ {input_file}: {e}")
        return

    valid_sources = []
    print("\nğŸ“¡ Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù†Ø§Ø¨Ø¹ RSS:\n")

    for source in sources:
        name = source.get("name")
        url = source.get("url")
        try:
            response = requests.get(url, timeout=10, headers={"User-Agent": "Mozilla/5.0"})
            response.raise_for_status()

            soup = BeautifulSoup(response.content, "xml")
            items = soup.find_all("item")

            if len(items) >= 1:
                print(f"âœ… Ù…Ø¹ØªØ¨Ø±: {name} â†’ ØªØ¹Ø¯Ø§Ø¯ Ø®Ø¨Ø±Ù‡Ø§: {len(items)}")
                valid_sources.append(source)
            else:
                print(f"âš ï¸ Ø®Ø§Ù„ÛŒ ÛŒØ§ Ø¨Ø¯ÙˆÙ† Ø®Ø¨Ø±: {name}")
        except Exception as e:
            print(f"âŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {name} â†’ Ø®Ø·Ø§: {e}")

    try:
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(valid_sources, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ“ Ù…Ù†Ø§Ø¨Ø¹ Ø³Ø§Ù„Ù… Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯ Ø¯Ø± ÙØ§ÛŒÙ„: {output_file}")
    except Exception as e:
        print(f"â—ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù†ÙˆØ´ØªÙ† ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ: {e}")

if __name__ == "__main__":
    validate_sources()
