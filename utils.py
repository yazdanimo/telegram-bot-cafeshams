import feedparser
import re
import json
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse

def load_sources():
    try:
        with open("sources.json", "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ sources.json â†’ {e}")
        return []

def parse_rss(url):
    feed = feedparser.parse(url)
    return feed.entries if feed and feed.entries else []

def extract_full_content(html):
    soup = BeautifulSoup(html, "html.parser")

    # Ø­Ø°Ù Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
    for tag in soup(["script", "style", "header", "footer", "nav"]):
        tag.decompose()

    # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…Ù‚Ø§Ù„Ù‡ ÛŒØ§ Ù…Ø­ØªÙˆØ§ÛŒ Ø§ØµÙ„ÛŒ
    content = ""
    for tag_name in ["article", "main", "div", "section"]:
        el = soup.find(tag_name)
        if el:
            content = el.get_text(separator=" ", strip=True)
            break

    if not content:
        content = soup.get_text(separator=" ", strip=True)

    # ÙÛŒÙ„ØªØ± Ø®Ø·ÙˆØ· Ø®ÛŒÙ„ÛŒ Ú©ÙˆØªØ§Ù‡
    lines = [line.strip() for line in content.splitlines() if len(line.strip()) > 40]
    return "\n".join(lines[:15])

def summarize_text(text):
    lines = [line.strip() for line in text.splitlines() if line.strip()]
    return "\n".join(lines[:3])  # Ø³Ù‡ Ø®Ø· Ø§ÙˆÙ„ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø®Ù„Ø§ØµÙ‡

def format_news(source, title, summary, link):
    return (
        f"<b>{source}</b>\n\n"
        f"ğŸ“° <b>{title}</b>\n\n"
        f"{summary}\n\n"
        f"ğŸ”— <a href='{link}'>{link}</a>"
    )

def translate_text(text):
    try:
        response = requests.post(
            "https://translate.argosopentech.com/translate",
            json={"q": text, "source": "en", "target": "fa"},
            timeout=10
        )
        if response.status_code == 200 and "translatedText" in response.json():
            return response.json()["translatedText"]
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªØ±Ø¬Ù…Ù‡ â†’ {e}")
    return text  # Ø§Ú¯Ø± ØªØ±Ø¬Ù…Ù‡ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯ØŒ Ù…ØªÙ† Ø§ØµÙ„ÛŒ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯

def is_persian(text):
    return bool(re.search(r"[\u0600-\u06FF]", text))
