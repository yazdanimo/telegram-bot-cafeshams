import feedparser
import re
import json
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
from googletrans import Translator

# Ù…ØªØ±Ø¬Ù… Ù…Ø­Ù„ÛŒ Ø¨Ø§ googletrans
translator = Translator()

def load_sources(path="sources.json"):
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù„ÛŒØ³Øª Ù…Ù†Ø§Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ Ø§Ø² ÙØ§ÛŒÙ„ JSON."""
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ {path} â†’ {e}")
        return []

def parse_rss(url):
    """Ø®ÙˆØ§Ù†Ø¯Ù† RSS Ùˆ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù„ÛŒØ³Øª Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§."""
    feed = feedparser.parse(url)
    return feed.entries if feed and feed.entries else []

def extract_full_content(html):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø§ØµÙ„ÛŒ ØµÙØ­Ù‡ Ø¨Ø§ BeautifulSoup."""
    soup = BeautifulSoup(html, "html.parser")
    for tag in soup(["script", "style", "header", "footer", "nav"]):
        tag.decompose()

    content = ""
    for section in ["article", "main", "div", "section"]:
        el = soup.find(section)
        if el:
            content = el.get_text(separator=" ", strip=True)
            break
    if not content:
        content = soup.get_text(separator=" ", strip=True)

    # ÙÛŒÙ„ØªØ± Ø®Ø·ÙˆØ· Ú©ÙˆØªØ§Ù‡
    lines = [ln.strip() for ln in content.splitlines() if len(ln.strip()) > 60]
    return "\n".join(lines[:10]) or "Ù…ØªÙ† Ù‚Ø§Ø¨Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø¨ÙˆØ¯."

def summarize_text(text):
    """Ø®Ù„Ø§ØµÙ‡ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø§ Ø¨Ø±Ø´ Ø¯Ùˆ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù Ø§ÙˆÙ„."""
    paras = text.split("\n\n")
    good = [p.strip() for p in paras if len(p.strip()) > 80]
    return "\n\n".join(good[:2]) or "Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."

def translate_text(text):
    """ØªØ±Ø¬Ù…Ù‡ Ù…ØªÙ† Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ googletrans."""
    try:
        result = translator.translate(text, src="en", dest="fa")
        return result.text
    except Exception as e:
        print(f"âš ï¸ ØªØ±Ø¬Ù…Ù‡ Ø§Ù†Ø¬Ø§Ù… Ù†Ø´Ø¯ â†’ {e}")
        return text

def format_news(source, title, summary, link):
    """Ù‚Ø§Ù„Ø¨â€ŒØ¨Ù†Ø¯ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø®Ø¨Ø± Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…."""
    # Ø­ØªÙ…Ø§ Ù„ÛŒÙ†Ú© Ø±Ø§ Ù‚Ø§Ø¨Ù„ Ú©Ù„ÛŒÚ© Ù†Ú¯Ù‡â€ŒØ¯Ø§Ø±ÛŒØ¯
    return (
        f"ğŸ“° <b>{source}</b>\n\n"
        f"<b>{title}</b>\n\n"
        f"{summary.strip()}\n\n"
        f"ğŸ”— <a href='{link}'>Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ø§Ù…Ù„ Ø®Ø¨Ø±</a>\n"
        f"ğŸ†” @CafeShams"
    )
