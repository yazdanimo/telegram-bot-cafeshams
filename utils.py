# File: utils.py

import feedparser
import re
import json
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse

TRANSLATE_API_URL = "https://libretranslate.de/translate"

def load_sources(path="sources.json"):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ {path} â†’ {e}")
        return []

def parse_rss(url):
    feed = feedparser.parse(url)
    return feed.entries if feed and feed.entries else []

def extract_full_content(html):
    soup = BeautifulSoup(html, "html.parser")
    for tag in soup(["script", "style", "header", "footer", "nav"]):
        tag.decompose()

    # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…Ø­ØªÙˆÛŒØ§Øª Ø§ØµÙ„ÛŒ
    content = ""
    for section in ("article", "main", "div", "section"):
        el = soup.find(section)
        if el:
            content = el.get_text(separator="\n", strip=True)
            break

    if not content:
        content = soup.get_text(separator="\n", strip=True)

    # ÙÛŒÙ„ØªØ± Ø®Ø·ÙˆØ· ØºÛŒØ±Ù…ÙÛŒØ¯ Ùˆ Ù…ØªØ§Ø¯ÛŒØªØ§ (Ù„ÛŒÙ†Ú© ÛŒØ§ ØªØ§Ø±ÛŒØ®)
    raw_lines = content.splitlines()
    filtered = []
    for ln in raw_lines:
        ln = ln.strip()
        if len(ln) < 60:
            continue
        if ln.startswith("http"):
            continue
        # Ø­Ø°Ù Ø®Ø·ÙˆØ· ØªØ§Ø±ÛŒØ® ÙØ§Ø±Ø³ÛŒ Ø³Ø§Ø¯Ù‡ (Ù…Ø«Ø§Ù„: "Û²Û± ØªÛŒØ± Û±Û´Û°Û´ØŒ Û±:Û±Û°")
        if re.match(r"^\d{1,2}\s+\w+\s+\d{4}", ln):
            continue
        filtered.append(ln)

    return " ".join(filtered)

def summarize_text(text):
    # Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù† Ø¬Ù…Ù„Ø§Øª Ùˆ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø¯Ùˆ Ø¬Ù…Ù„Ù‡ Ø§ÙˆÙ„
    sentences = re.split(r"(?<=[.!?])\s+", text)
    if len(sentences) >= 2:
        return " ".join(sentences[:2]).strip()
    return text[:200].strip() + "..."

def is_english(text):
    return bool(re.search(r"[A-Za-z]", text))

def translate_text(text):
    try:
        resp = requests.post(
            TRANSLATE_API_URL,
            json={"q": text, "source": "en", "target": "fa", "format": "text"},
            timeout=10
        )
        if resp.status_code == 200:
            return resp.json().get("translatedText", text)
    except Exception as e:
        print(f"âš ï¸ ØªØ±Ø¬Ù…Ù‡ Ø§Ù†Ø¬Ø§Ù… Ù†Ø´Ø¯ â†’ {e}")
    return text

def format_news(source, title, summary, link):
    # ØªØ±Ø¬Ù…Ù‡ Ø¹Ù†Ø§ÙˆÛŒÙ† ÛŒØ§ Ø®Ù„Ø§ØµÙ‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
    if is_english(title):
        title = translate_text(title)
    if is_english(summary):
        summary = translate_text(summary)

    return (
        f"ğŸ“° <b>{source}</b>\n\n"
        f"<b>{title.strip()}</b>\n\n"
        f"{summary.strip()}\n\n"
        f"ğŸ”— <a href='{link}'>Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ø§Ù…Ù„ Ø®Ø¨Ø±</a>\n"
        f"ğŸ†” @cafeshamss     \n"
        f"Ú©Ø§ÙÙ‡ Ø´Ù…Ø³ â˜•ï¸ğŸª"
    )
